#!/usr/bin/env python
# coding: utf-8


import torch
from torchvision import models, transforms
from PIL import Image

# ------------------------------------------------------------
# 1. è¨­å®š label åç¨±ï¼ˆä¾ä½ è¨“ç·´æ™‚é †åºï¼‰
# ------------------------------------------------------------
class_names = ["2ch", "4ch"]

# ------------------------------------------------------------
# 2. è¼‰å…¥æ¨¡å‹
# ------------------------------------------------------------
def load_model(weight_path="densenet121_cvus.pth"):
    model = models.densenet121(weights=None)
    model.classifier = torch.nn.Linear(model.classifier.in_features, 2)
    model.load_state_dict(torch.load(weight_path, map_location="cpu"))
    model.eval()
    print("æ¨¡å‹è¼‰å…¥å®Œæˆï¼")
    return model

# ------------------------------------------------------------
# 3. Transformï¼ˆå‹™å¿…èˆ‡ä½ è¨“ç·´æ™‚ç›¸åŒï¼‰
# ------------------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# ------------------------------------------------------------
# 4. å–®å¼µåœ–ç‰‡æ¨è«–
# ------------------------------------------------------------
def predict_image(model, img_path):
    img = Image.open(img_path).convert("RGB")
    img_tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        outputs = model(img_tensor)
        _, pred = torch.max(outputs, 1)

    label = class_names[pred.item()]
    print(f"ğŸ“Œ é æ¸¬çµæœï¼š {label}")
    return label

# ------------------------------------------------------------
# 5. è¼‰å…¥æ¨¡å‹ä¸¦æ¸¬è©¦
# ------------------------------------------------------------
model = load_model("densenet121_cvus_20251201.pth")

# ä¿®æ”¹æˆä½ çš„ PNG åœ–ç‰‡è·¯å¾‘
img_path = "000.png"

predict_image(model, img_path)






